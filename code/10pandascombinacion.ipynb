{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelCaballero/Julio24/blob/main/code/10pandascombinacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYeSOuO34P2L"
      },
      "source": [
        "\n",
        "# Introducción a la ciencia de datos con Python\n",
        "### Rafa Caballero\n",
        "\n",
        "### Combinando dataframes\n",
        "Veamos en este Notebook cómo se combinan y agregan dataframes\n",
        "\n",
        "### Índice\n",
        "[Concatenar](#Concatenar)<br>\n",
        "[Merge](#Merge)<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcg7cK-mZ9wJ"
      },
      "source": [
        "El siguiente código es para mostrar una dataframe al lado de otro, ejecutarlo pero no hace falta entenderlo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkiuTnjuZ9wJ"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "from IPython.display import display_html\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def display_side_by_side(*args,title=\"\"):\n",
        "    print(title)\n",
        "    html_str = ''\n",
        "    for df in args:\n",
        "        html_str += '&nbsp;&nbsp;&nbsp;'+df.to_html()\n",
        "    display_html(\n",
        "        html_str.replace('table','table style=\"display:inline\"'),\n",
        "        raw=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWv_3g-JZ9wK"
      },
      "source": [
        "<a name=\"Concatenar\"></a>\n",
        "### Concatenar\n",
        "\n",
        "La forma más fácil, y a veces la más rápida y útil, de combinar dataframes, ya sea \"pegándolo\" debajo o al lado con `pd.concat`\n",
        "\n",
        "<img src = \"https://miro.medium.com/max/1050/1*0wu6DunCzPC4o9FIyRTW4w.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXln3OwOZ9wK"
      },
      "outputs": [],
      "source": [
        "import IPython.display as display\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from random import sample\n",
        "\n",
        "\n",
        "df1 = DataFrame({'clave': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
        "                 'data': range(7),\n",
        "                 'otro': sample(range(10, 30), 7)})\n",
        "\n",
        "df2 = DataFrame({'clave': ['e', 'e', 'e', 'e'],\n",
        "                 'data': range(4),\n",
        "                 'otro': sample(range(10, 30), 4)})\n",
        "\n",
        "display_side_by_side(df1,df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLIg0c2FZ9wL"
      },
      "outputs": [],
      "source": [
        "df3 = pd.concat([df1,df2])\n",
        "df3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af-DjXo1Z9wM"
      },
      "source": [
        "Si nos incomoda que el índice no sea consecutivo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thzBeGbIZ9wM"
      },
      "outputs": [],
      "source": [
        "df3 = df3.reset_index(drop=True)\n",
        "df3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daOZj_UrZ9wM"
      },
      "source": [
        "Sin embargo, hay veces que es útil usar el índice (si no tiene ya otro cometido) para \"apuntar\" el origen de cada fila"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lS3bS2aZ9wN"
      },
      "outputs": [],
      "source": [
        "import IPython.display as display\n",
        "import pandas as pd\n",
        "\n",
        "df1 = DataFrame({'clave': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
        "                 'data': range(7),\n",
        "                 'otro': sample(range(10, 30), 7)})\n",
        "\n",
        "df2 = DataFrame({'clave': ['e', 'e', 'e', 'e'],\n",
        "                 'data': range(4),\n",
        "                 'otro': sample(range(10, 30), 4)})\n",
        "\n",
        "df1.index = [\"A\"]*len(df1)\n",
        "df2.index = [\"B\"]*len(df2)\n",
        "display_side_by_side(df1,df2,pd.concat([df1,df2]),title=\"pd.concat([df1,df2])\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8r2H6pHZ9wN"
      },
      "source": [
        "**Ojo** porque `concat` no es tan *tonto* como parece; no se limita a pegar debajo sino que alinea por nombres de columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26FpjnGIZ9wO"
      },
      "outputs": [],
      "source": [
        "import IPython.display as display\n",
        "import pandas as pd\n",
        "\n",
        "df1 = DataFrame({'clave': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
        "                 'data': range(7),\n",
        "                 'otro': sample(range(10, 30), 7)})\n",
        "\n",
        "df2 = DataFrame({'clave': ['e', 'e', 'e', 'e'],\n",
        "                 'otro': sample(range(10, 30), 4),\n",
        "                 'data': range(4) } )\n",
        "\n",
        "df1.index = [\"A\"]*len(df1)\n",
        "df2.index = [\"B\"]*len(df2)\n",
        "display_side_by_side(df1,df2,pd.concat([df1,df2]), title=\"pd.concat([df1,df2])\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFyRc5SCZ9wO"
      },
      "source": [
        "Con el parámetro axis (que por defecto vale 0) podemos hacer que en lugar de por filas concatene por columnas. En este caso lo lógico es que ambos dataframes tengan el mismo número de filas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd7e0zqkZ9wP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "filas = 5\n",
        "df1 = DataFrame({'A': np.random.randint(1,10,filas) ,\n",
        "                 'B': np.random.randint(1,10,filas),\n",
        "                 'C': np.random.randint(1,10,filas)})\n",
        "\n",
        "df2 = DataFrame({'D': np.random.randint(2000,3000,filas),\n",
        "                 'E': np.random.randint(2000,3000,filas)})\n",
        "display_side_by_side(df1,df2, pd.concat([df1,df2],axis=1),\n",
        "                     title=\"pd.concat([df1,df2],axis=1)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hthu825pZ9wP"
      },
      "source": [
        "Un aspecto muy importante: igual que al concatenar utiliza los nombres de columna aquí va a usar los números de fila"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yw_w_iMZ9wP"
      },
      "outputs": [],
      "source": [
        "df2.index=[0,1,2,4,7]\n",
        "display_side_by_side(df1,df2, pd.concat([df1,df2],axis=1),\n",
        "                     title=\"pd.concat([df1,df2],axis=1)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_s9Suq8Z9wP"
      },
      "source": [
        "Si el número de filas o columnas no encaja, `concat` añadirá valores vacío para completar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8C_KRaLZ9wP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "filas = 5\n",
        "df1 = DataFrame({'A': np.random.randint(1,10,filas) ,\n",
        "                 'B': np.random.randint(1,10,filas),\n",
        "                 'C': np.random.randint(1,10,filas)})\n",
        "\n",
        "df2 = DataFrame({'D': np.random.randint(2000,3000,filas-1),\n",
        "                 'E': np.random.randint(2000,3000,filas-1)})\n",
        "display_side_by_side(df1,df2, pd.concat([df1,df2],axis=1),title=\"pd.concat([df1,df2],axis=1)\")\n",
        "\n",
        "display_side_by_side(df1,df2, pd.concat([df1,df2],axis=0),title=\"pd.concat([df1,df2],axis=0)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1dFLeq9Z9wQ"
      },
      "source": [
        "**Ejercicio**  El siguiente código descarga tres ficheros con datos diarios de metereología en Madrid y sus metadatos a una carpeta ./raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebhJbiNCZ9wQ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "path = Path.cwd()\n",
        "pathraw = Path(path,\"raw\")\n",
        "\n",
        "pathraw.mkdir(exist_ok=True)\n",
        "\n",
        "datos = [\"https://datos.madrid.es/FWProjects/egob/Catalogo/MedioAmbiente/DatosMeteorologicos/Ficheros/Interpretaci%C3%B3n_datos_meteorologicos.pdf\",\n",
        "         \"https://datos.madrid.es/egob/catalogo/300351-0-meteorologicos-diarios.csv\",\n",
        "         \"https://datos.madrid.es/egob/catalogo/300351-3-meteorologicos-diarios.csv\",\n",
        "          \"https://datos.madrid.es/egob/catalogo/300351-9-meteorologicos-diarios.csv\"]\n",
        "locales = []\n",
        "for url in datos:\n",
        "    nombre = Path(url).name\n",
        "    camino = Path(pathraw,nombre)\n",
        "    r = requests.get(url, allow_redirects=True) # el fichero queda en la variable r\n",
        "    if r.status_code==200:\n",
        "        with open(camino, 'wb') as f:\n",
        "            f.write(r.content) # ahora lo grabamos localmente\n",
        "        print(\"Grabado,\",camino)\n",
        "        locales.append(camino)\n",
        "    else:\n",
        "        print(\"Error descargando \",url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBFfk_qwZ9wQ"
      },
      "outputs": [],
      "source": [
        "locales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjOK9cskZ9wR"
      },
      "source": [
        "Añadir código para combinar los 3 ficheros en uno solo sabiendo que tienen las mismas columnas y que sus caminos están en la variable `locales`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pwFA2ymZ9wR"
      },
      "outputs": [],
      "source": [
        "# primero leemos todos los ficheros; dfs será una lista de dataframes\n",
        "dfs = []\n",
        "for p in locales:\n",
        "    if p.suffix==\".csv\":\n",
        "        df_temp = pd.read_csv(p,sep=\";\")\n",
        "        dfs.append(df_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-O5bOBlZ9wR"
      },
      "outputs": [],
      "source": [
        "df = pd.concat(dfs)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kid6oPQFZ9wS"
      },
      "outputs": [],
      "source": [
        "df.MAGNITUD.unique()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycPnBXy74P2U"
      },
      "source": [
        "<a name=\"Merge\"></a>\n",
        "### Merge\n",
        "\n",
        "En este caso se busca unir dos dataframes fijándonos en las coincidencias entre valores de dos columnas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDzGNj1j4P2X"
      },
      "outputs": [],
      "source": [
        "from pandas import DataFrame\n",
        "from pandas import Series\n",
        "import pandas as pd\n",
        "from random import sample\n",
        "df1 = DataFrame({'clave': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
        "                 'data1': range(7),\n",
        "                 'otro': sample(range(10, 30), 7)})\n",
        "\n",
        "df2 = DataFrame({'clave': ['a', 'b', 'b', 'd'],\n",
        "                 'data2': range(4)})\n",
        "display_side_by_side(df1,df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "env2fCpvZ9wS"
      },
      "source": [
        "Por defecto la mezcla es por la columna que se llama igual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHASYRX64P2a"
      },
      "outputs": [],
      "source": [
        "\n",
        "display_side_by_side(df1,df2, pd.merge(df1,df2),title=\"pd.merge(df1,df2)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qDjuyix4P2c"
      },
      "source": [
        "Si no se indica lo contrario, `merge` busca columnas comunes y hace un (inner) 'join'. Nótese que en este caso no se tienen en cuenta los índices\n",
        "<br><br>\n",
        "\n",
        "El método merge se puede llamar también dentro de un dataframe (es equivalente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNzwLqaI6Wm4"
      },
      "outputs": [],
      "source": [
        "df1.merge(df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C64nnTQU7uow"
      },
      "source": [
        "También se pueden unir por varias columnas, que podemos especificar directamente con los parámetros `left_on`y `right_on`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzxyoozG6P3w"
      },
      "outputs": [],
      "source": [
        "\n",
        "df3 = df1.merge(df2, left_on=['clave','data1'], right_on = ['clave','data2'])\n",
        "\n",
        "display_side_by_side(df1,df2, df3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqT6d_LH799A"
      },
      "source": [
        "Si la clave o claves por las que querenos unir se llaman ambas igual podemos usar simplemente `on`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMtV8g8P4P2d"
      },
      "outputs": [],
      "source": [
        "df3 = pd.merge(df1,df2,on='clave')\n",
        "display_side_by_side(df1,df2, df3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoAFxQkh4P2k"
      },
      "source": [
        "Además de *inner* join, se pueden hacer con el parámetro `how` tomando valores *left*, *right*, *outer*, *inner*\n",
        "\n",
        "<img src=\"https://www.golinuxcloud.com/wp-content/uploads/types_joins-1320x961.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNPUGlHk_nI4"
      },
      "source": [
        "En el caso de left, right y full/outer si la columna no encaja se rellenan con valores NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbqvqDKL4P2l"
      },
      "outputs": [],
      "source": [
        "df3 = df1.merge( df2, on='clave', how='left')\n",
        "display_side_by_side(df1,df2, df3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfe8AZRsCy-g"
      },
      "source": [
        "**Ejercicio** En\n",
        "\n",
        "https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/tweetsCompletadoOrdenRename.csv\n",
        "\n",
        "Tenemos datos de tweets, incluyendo el identificador del usuario que que ha emitidos cada tweet,  `userid`.\n",
        "\n",
        "En\n",
        "\n",
        "https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/usersrentaf.csv\n",
        "\n",
        "tenemos datos de usuarios: sú número de seguidores, la renta de la zona donde viven, etc. En este caso el identificador se llama simplemente `id`.\n",
        "\n",
        "Queremos unir ambos ficheros, de forma que a cada tweet se le añadan los datos de su usuario. Si un tweet no tiene su usario en el segundo conjunto de datos debemos borrarlo. Igualmente si un usuario no tiene ningún tweet no se incluirá.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1f4TfgnCxr5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "url_tweets = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/tweetsCompletadoOrdenRename.csv\"\n",
        "url_users = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/usersrentaf.csv\"\n",
        "df_tweets = pd.read_csv(url_tweets)\n",
        "df_users = pd.read_csv(url_users)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U7D6ooaJ5ca"
      },
      "outputs": [],
      "source": [
        "df_tweets.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6JWkDKEZ9wV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xx8oFulZ9wW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}