{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelCaballero/Julio24/blob/main/code/23Hiperpar%C3%A1metros.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d0d9452",
      "metadata": {
        "id": "4d0d9452"
      },
      "source": [
        "# Introducción a la ciencia de datos con Python\n",
        "Rafa Caballero\n",
        "\n",
        "## Ajuste de hiperparámetros\n",
        "\n",
        "### Índice\n",
        "[Ajuste de parámetros uno a uno](#amano)<br>\n",
        "[GridSearchCV](#GridSearchCV)<br>\n",
        "[RandomizedSearchCV](#RandomizedSearchCV)<br>\n",
        "\n",
        "Empezamos cargando las librerías y los datos que vamos a usar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96476499",
      "metadata": {
        "id": "96476499"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, train_test_split,cross_val_predict\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import cohen_kappa_score,make_scorer,confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "path = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/movimiento.csv\"\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b17c6cc",
      "metadata": {
        "id": "7b17c6cc"
      },
      "source": [
        "Se trata de datos tomados de los sensores de móviles en periodos de pocos segundos, nuestro objetivo es averiguar la actividad que está realizando la persona que lleva el móvil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0c64b5d",
      "metadata": {
        "id": "f0c64b5d"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cdb12aa",
      "metadata": {
        "id": "9cdb12aa"
      },
      "source": [
        "**Ejercicio** Ver cuántos valores diferentes toma df.target y la frecuencia de cada uno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce1ba21b",
      "metadata": {
        "id": "ce1ba21b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8f4d31ce",
      "metadata": {
        "id": "8f4d31ce"
      },
      "source": [
        "No tendremos que usar nungún tipo de sampling (over, under, SMOTE...), está muy equilibrado. Aunque no lo hagamos en detalle habría que ver histogramas, outlayers y correlaciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33dfd561",
      "metadata": {
        "id": "33dfd561"
      },
      "outputs": [],
      "source": [
        "df.accelerometer_mean.hist(bins=30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96c9698",
      "metadata": {
        "id": "d96c9698"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "correlaciones = df.corr(numeric_only=True)\n",
        "g = sns.clustermap(correlaciones,\n",
        "                   method = 'complete',\n",
        "                   cmap   = 'RdBu',\n",
        "                   annot  = True,\n",
        "                   annot_kws = {'size': 8})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022c6c05",
      "metadata": {
        "id": "022c6c05"
      },
      "source": [
        "\n",
        "\n",
        "<a name=\"amano\"></a>\n",
        "#### Ajuste de los parámetros uno a uno\n",
        "\n",
        "Empleamos KNN para adivinar el tipo de movimiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de9dd7d8",
      "metadata": {
        "id": "de9dd7d8"
      },
      "outputs": [],
      "source": [
        "\n",
        "etiquetas = ['Quieto','Coche','Tren','Autobús','Andando']\n",
        "\n",
        "#1\n",
        "yColumn=\"label\"\n",
        "XColumns = [c for c in df.columns if c!=yColumn and c!='target']\n",
        "\n",
        "X = df[XColumns]\n",
        "y = df[yColumn]\n",
        "\n",
        "# 2\n",
        "test = 0.4\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)\n",
        "\n",
        "# 3\n",
        "steps = [('StandardScaler', StandardScaler()),('KNN', KNeighborsClassifier())]\n",
        "metodo = Pipeline(steps=steps)\n",
        "modelo = metodo.fit(X_train,y_train)\n",
        "\n",
        "# 4\n",
        "y_pred = modelo.predict(X_test)\n",
        "\n",
        "kappa= cohen_kappa_score(y_test,y_pred)\n",
        "print(\"Kappa \",kappa)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=modelo.classes_,normalize=\"true\")\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=etiquetas)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87c374e3",
      "metadata": {
        "id": "87c374e3"
      },
      "source": [
        "Kappa con validación cruzada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3897f489",
      "metadata": {
        "id": "3897f489"
      },
      "outputs": [],
      "source": [
        "scorer = make_scorer(cohen_kappa_score)\n",
        "\n",
        "steps = [('StandardScaler', StandardScaler()),('KNN', KNeighborsClassifier())]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "cv = RepeatedStratifiedKFold(n_splits=20, n_repeats=10)\n",
        "scores = cross_val_score(pipeline, X, y, scoring=scorer, cv=cv)\n",
        "kappa= scores.mean()\n",
        "print(\"Kappa \",kappa)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d56f48d",
      "metadata": {
        "id": "9d56f48d"
      },
      "source": [
        "**Ejercicio** En el código anterior probar a cambiar `StandardScaler()` por `MinMaxScaler()`, y también por nada, elegir la mejor opción"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cc590be",
      "metadata": {
        "id": "8cc590be"
      },
      "source": [
        "Probamos a quitar algunas de las columnas correlacionadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e71fa24",
      "metadata": {
        "id": "5e71fa24"
      },
      "outputs": [],
      "source": [
        "borrar = [\"accelerometer_max\",\"gyroscope_max\",\"gyroscope_std\",\"sound_max\",\"sound_min\"]\n",
        "X2 = X.drop(columns=borrar)\n",
        "steps = [('StandardScaler', StandardScaler()),('KNN', KNeighborsClassifier())]\n",
        "scores = cross_val_score(pipeline, X2, y, scoring=scorer, cv=cv)\n",
        "kappa= scores.mean()\n",
        "print(\"Kappa \",kappa)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5765c70",
      "metadata": {
        "id": "a5765c70"
      },
      "source": [
        "Empeora ligeramente, pero simplifica el dataframe y puede dar buen resultado con otros métodos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cefa1ae",
      "metadata": {
        "id": "9cefa1ae"
      },
      "outputs": [],
      "source": [
        "X=X2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d6bc031",
      "metadata": {
        "id": "7d6bc031"
      },
      "source": [
        "Vamos a determinar el mejor valor de $k$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee9429c3",
      "metadata": {
        "id": "ee9429c3"
      },
      "outputs": [],
      "source": [
        "\n",
        "ks = []\n",
        "kappas = []\n",
        "for k in range(1,12):\n",
        "    steps = [('StandardScaler', StandardScaler()),('KNN', KNeighborsClassifier(n_neighbors=k))]\n",
        "    pipeline = Pipeline(steps=steps)\n",
        "    cv = RepeatedStratifiedKFold(n_splits=20, n_repeats=10)\n",
        "    scores = cross_val_score(pipeline, X, y, scoring=scorer, cv=cv)\n",
        "    kappa= scores.mean()\n",
        "    print(k,kappa)\n",
        "    ks.append(k)\n",
        "    kappas.append(kappa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6c09547",
      "metadata": {
        "id": "e6c09547"
      },
      "outputs": [],
      "source": [
        "plt.plot(ks,kappas)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92a70494",
      "metadata": {
        "id": "92a70494"
      },
      "source": [
        "Por tanto elegimos k=3. Ahora tenemos que elegir la distancia. Utilizar k=3, no hace falta gráfica (no tiene sentido)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9bbe932",
      "metadata": {
        "id": "a9bbe932"
      },
      "outputs": [],
      "source": [
        "distances = ['minkowski','cosine', 'chebyshev', 'euclidean',  'manhattan']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ba0fa61",
      "metadata": {
        "id": "2ba0fa61"
      },
      "source": [
        "Vamos a ver si merece la pena considerar con más peso a los vecinos más cercanos o solo \"contar\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03043552",
      "metadata": {
        "id": "03043552"
      },
      "outputs": [],
      "source": [
        "weights = ['uniform', 'distance']\n",
        "for w in weights:\n",
        "    steps = [('StandardScaler', StandardScaler()),('KNN', KNeighborsClassifier(n_neighbors=3,metric='manhattan',weights=w))]\n",
        "    pipeline = Pipeline(steps=steps)\n",
        "    cv = RepeatedStratifiedKFold(n_splits=20, n_repeats=10)\n",
        "    scores = cross_val_score(pipeline, X, y, scoring=scorer, cv=cv)\n",
        "    kappa= scores.mean()\n",
        "    print(w,kappa)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aad5543e",
      "metadata": {
        "id": "aad5543e"
      },
      "source": [
        "Recapitulamos comparando, primero sin hiperparámetros y luego con los que hemos encontrado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3162c2",
      "metadata": {
        "id": "ce3162c2"
      },
      "outputs": [],
      "source": [
        "etiquetas = ['Quieto','Coche','Tren','Autobús','Andando']\n",
        "\n",
        "#1\n",
        "yColumn=\"label\"\n",
        "XColumns = [c for c in df.columns if c!=yColumn and c!='target' and c not in borrar]\n",
        "\n",
        "X = df[XColumns]\n",
        "y = df[yColumn]\n",
        "\n",
        "# 2\n",
        "test = 0.4\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)\n",
        "\n",
        "# 3\n",
        "steps = [('StandardScaler', StandardScaler()),('KNN', KNeighborsClassifier())]\n",
        "metodo = Pipeline(steps=steps)\n",
        "modelo = metodo.fit(X_train,y_train)\n",
        "\n",
        "# 4\n",
        "y_pred = modelo.predict(X_test)\n",
        "\n",
        "kappa= cohen_kappa_score(y_test,y_pred)\n",
        "print(\"Kappa \",kappa)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=modelo.classes_,normalize=\"true\")\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=etiquetas)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72015ca9",
      "metadata": {
        "id": "72015ca9"
      },
      "outputs": [],
      "source": [
        "# 3\n",
        "steps = [('StandardScaler', StandardScaler()),('KNN', KNeighborsClassifier(n_neighbors=3,metric='manhattan',weights='distance'))]\n",
        "metodo = Pipeline(steps=steps)\n",
        "modelo = metodo.fit(X_train,y_train)\n",
        "\n",
        "# 4\n",
        "y_pred = modelo.predict(X_test)\n",
        "\n",
        "kappa= cohen_kappa_score(y_test,y_pred)\n",
        "print(\"Kappa \",kappa)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=modelo.classes_,normalize=\"true\")\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=etiquetas)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f2e1011",
      "metadata": {
        "id": "9f2e1011"
      },
      "source": [
        "<a name=\"GridSearchCV\"></a>\n",
        "#### GridSearchCV\n",
        "\n",
        "Como vemos el método ha sido muy laborioso. Además nada nos asegura que si hubiéramos puesto \"manhattan\" al principio, por ejemplo, no hubiera salido un k diferente. Si queremos asegurar de que eso no pasa tenemos que probar ¡todas las combinaciones de todos los parámetros enter sí! Así aseguraremos que elegimos la mejor combinación, pero con un coste en tiempo altísimo.\n",
        "\n",
        "De eso se encarga GridSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7233f1fc",
      "metadata": {
        "id": "7233f1fc"
      },
      "outputs": [],
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbe8effd",
      "metadata": {
        "id": "fbe8effd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "paramGrid = {'KNN__n_neighbors': list(range(1,12)),\n",
        "             'KNN__metric': ['minkowski','cosine', 'chebyshev', 'euclidean',  'manhattan'],\n",
        "             'KNN__weights': ['uniform', 'distance']\n",
        "            }\n",
        "\n",
        "steps = [('StandardScaler', StandardScaler()),('KNN', KNeighborsClassifier())]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "\n",
        "metodo = GridSearchCV(pipeline, paramGrid,cv=cv,scoring=scorer,n_jobs=-1,refit=True)\n",
        "modelo = metodo.fit(X,y)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b31936ab",
      "metadata": {
        "id": "b31936ab"
      },
      "source": [
        "Podemos ver el mejor kappa, con qué parámetros se consigue y cuál es el pipeline asociado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfcb68fa",
      "metadata": {
        "scrolled": true,
        "id": "dfcb68fa"
      },
      "outputs": [],
      "source": [
        "print(modelo.best_score_)\n",
        "print(modelo.best_params_)\n",
        "print(modelo.best_estimator_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39024195",
      "metadata": {
        "id": "39024195"
      },
      "source": [
        "Hemos puesto `refit=True` para que tras encontrar los mejores parámetros haga un último modelo con el conjunto completo y esos valores. Por eso `best_estimator_` es el mejor modelo con esos parámetros. Podemos grabarlo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d7daa35",
      "metadata": {
        "id": "7d7daa35"
      },
      "outputs": [],
      "source": [
        "from joblib import dump, load\n",
        "estimator = modelo.best_estimator_\n",
        "dump(estimator, \"modelo_sensores.joblib\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e0beb68",
      "metadata": {
        "id": "5e0beb68"
      },
      "source": [
        "Ahora en otro notebook podríamos hacer por ejemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8462955b",
      "metadata": {
        "id": "8462955b"
      },
      "outputs": [],
      "source": [
        "from joblib import dump, load\n",
        "model_sensor = load(\"modelo_sensores.joblib\")\n",
        "\n",
        "#        accelerometer_mean accelerometer_min accelerometer_std  gyroscope_mean  gyroscope_min  sound_mean  sound_std\n",
        "valor = [10.00,             9.00,              0.50,             0.183202,       0.020667,      89.770732,   0.006389]\n",
        "\n",
        "etiquetas = ['Quieto','Coche','Tren','Autobús','Andando']\n",
        "prediccion = model_sensor.predict([valor])\n",
        "print(etiquetas[prediccion[0]])\n",
        "print(model_sensor.predict_proba([valor]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ed0a381",
      "metadata": {
        "id": "7ed0a381"
      },
      "source": [
        "<a name=\"RandomizedSearchCV\"></a>\n",
        "#### RandomizedSearchCV\n",
        "\n",
        "La búsqueda \"en rejilla\" puede ser muy lenta; en el caso anterior hay 12x5x2=60, y comoen cv tenemos 20 particiones y 10 repeticiones, quedan 12000 modelos a entrenar. Para reducir este tiempo podemos utilizar `RandomizedSearchCV`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a220781",
      "metadata": {
        "id": "3a220781"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "metodo = RandomizedSearchCV(pipeline, paramGrid,cv=cv,scoring=scorer,n_jobs=-1,n_iter=25)\n",
        "modelo = metodo.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f405f68f",
      "metadata": {
        "id": "f405f68f"
      },
      "outputs": [],
      "source": [
        "print(modelo.best_score_)\n",
        "print(modelo.best_params_)\n",
        "print(modelo.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b00d8e57",
      "metadata": {
        "id": "b00d8e57"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}