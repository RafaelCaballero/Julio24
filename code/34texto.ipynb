{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelCaballero/Julio24/blob/main/code/34texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aada739d",
      "metadata": {
        "id": "aada739d"
      },
      "source": [
        "# Introducción a la ciencia de datos con Python\n",
        "Rafa Caballero\n",
        "\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "      <td>Análisis de textos\n",
        "      </td>\n",
        "      <td>\n",
        "      <img src=\"https://www.libreriadelprado.com/3720-large_default/la-mejor-cocinera-recetas-de-cocina.jpg\"  width=150/>\n",
        "      </td>\n",
        "     </tr>\n",
        "</table>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22229617",
      "metadata": {
        "id": "22229617"
      },
      "source": [
        "### Carga de bibliotecas y modelos de spaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e05c1aa9",
      "metadata": {
        "id": "e05c1aa9"
      },
      "outputs": [],
      "source": [
        "modules = [\"bs4\", \"spacy\", \"pandas\",\"seaborn\",\"scipy\",\"pysentimiento\",\n",
        "           \"accelerate==0.20.1\"]\n",
        "\n",
        "import sys\n",
        "import os.path\n",
        "from subprocess import check_call\n",
        "import importlib\n",
        "import os\n",
        "\n",
        "def instala(modules):\n",
        "  print(\"Instalando módulos\")\n",
        "  for m in modules:\n",
        "      # para el import quitamos [...] y ==...\n",
        "      p = m.find(\"[\")\n",
        "      mi = m if p==-1 else m[:p]\n",
        "      p = mi.find(\"==\")\n",
        "      mi = mi if p==-1 else mi[:p]\n",
        "\n",
        "      torch_loader = importlib.util.find_spec(mi)\n",
        "      if torch_loader is not None:\n",
        "          print(m,\" encontrado\")\n",
        "      else:\n",
        "          print(m,\" No encontrado, instalando...\",end=\"\")\n",
        "          try:\n",
        "            r = check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--user\", m])\n",
        "            print(\"¡hecho!\")\n",
        "          except:\n",
        "            print(\"¡Problema al instalar \",m,\"! ¿seguro que el módulo existe?\",sep=\"\")\n",
        "\n",
        "  print(\"¡Terminado!\")\n",
        "\n",
        "instala(modules)\n",
        "\n",
        "# ahora el modelo para español; ojo esto puede tardar y solo debe hacerse una vez, comentarlo tras la primera ejecución\n",
        "# tras ejecutarlo reiniciar (Entorno de Ejecución + Reiniciar entorno de ejecución)\n",
        "!python -m spacy download es_core_news_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19d3602c",
      "metadata": {
        "id": "19d3602c"
      },
      "outputs": [],
      "source": [
        "# cargamos el modelo\n",
        "#import es_core_news_md\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('es_core_news_md') #es_core_news_md.load()\n",
        "\n",
        "stops= [\"gramo\", \"gramos\",\"kilo\",\"kilos\",\"litro\", \"litros\",\"punto\",\"hora\",\"horas\",\"minuto\",\"minutos\",\"fuego\",\n",
        "        \"fuente\",\"cacerola\",\"horno\",\n",
        "       \"cucharada\",\"cucharadas\",\"trozo\",\"trozos\",\"molde\",\"moldes\"]\n",
        "[nlp.Defaults.stop_words.add(w) for w in stops]\n",
        "print(\"Listo!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6a6b072",
      "metadata": {
        "id": "e6a6b072"
      },
      "source": [
        " Cargamos el texto de la página:\n",
        "\n",
        "https://www.gutenberg.org/cache/epub/8870/pg8870.html  mediante requests (para obtener) y BeautifulSoup (para analizar y extraer el texto) dejándolo en una variable de nombre `texto`. Nos aseguramos de que `requests` no da error, mostrando un mensaje si el `status_code` es distinto de 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86a8b119",
      "metadata": {
        "id": "86a8b119"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "pagina = \"https://www.gutenberg.org/cache/epub/8870/pg8870.html\"\n",
        "\n",
        "page = requests.get(pagina)\n",
        "if page.status_code==200:\n",
        "    soup = BeautifulSoup(page.text, 'html.parser')  # le pasamos el texto en HTML para que lo analice\n",
        "    texto = soup.text\n",
        "else:\n",
        "    print(\"Error \", page.status_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06001e32",
      "metadata": {
        "id": "06001e32"
      },
      "source": [
        " Aplicamos el modelo `nlp`al `texto` dejando el resultado en una variable `doc`.\n",
        "A partir de `doc` extraer una lista de todos los lexemas en mayúsculas de los tokens que\n",
        "\n",
        "1) Sean valores alfauméricos\n",
        "2) No correspondan a palabras vacías\n",
        "3) Sean sustantivos\n",
        "\n",
        "El resultado será una lista de palabras en mayúscula (lexemas) que guardaremos en una variable `palabras`\n",
        "\n",
        "Ayuda: un token es un sustantivo si `token.pos_ == \"NOUN\"`. La palabra *pos* viene de *part of speech* e indica el tipo de palabra que es. Ver la [ayuda de spaCy](https://spacy.io/usage/linguistic-features) para un ejemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54215eba",
      "metadata": {
        "id": "54215eba"
      },
      "outputs": [],
      "source": [
        "doc = nlp(texto)\n",
        "palabras = [p.lemma_.upper() for p in doc\n",
        "            if p.is_alpha and not p.is_stop and p.pos_==\"NOUN\"]\n",
        "palabras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ad3123",
      "metadata": {
        "id": "18ad3123"
      },
      "source": [
        "Nos quedamos solo con las `N` palabras más frecuentes en `palabras` mediante el método `Counter`. El resultado sera una lista `frecuentes`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "250e84e6",
      "metadata": {
        "id": "250e84e6"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "N=25\n",
        "\n",
        "c = Counter(palabras)\n",
        "frecuentes = [p for p,_ in c.most_common(N)]\n",
        "frecuentes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca9625f",
      "metadata": {
        "id": "eca9625f"
      },
      "source": [
        "A partir de `doc` obtener una lista `frases`con todas las oraciones del libro en mayúsculas. El resultado esperado será de la forma:\n",
        "\n",
        "        ['\\n',\n",
        "         'THE PROJECT GUTENBERG EBOOK OF LA MEJOR COCINERA, RECETAS DE COCINA, BY CALLEJA\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTHE PROJECT GUTENBERG EBOOK OF LA MEJOR COCINERA...]\n",
        "\n",
        "(recordar que .text devuelve el texto asociado, ya sea a una palabra, una oración, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d94eab26",
      "metadata": {
        "id": "d94eab26"
      },
      "outputs": [],
      "source": [
        "frases = [o.text.upper() for o in doc.sents]\n",
        "\n",
        "# para probar\n",
        "frases[98:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "229de5e7",
      "metadata": {
        "id": "229de5e7"
      },
      "source": [
        "Ahora escribimos una función:\n",
        "\n",
        "Nombre `palabrasEnFrase`\n",
        "\n",
        "Parámetros:\n",
        "\n",
        "    palabras: una lista de strings representando palabras\n",
        "    frase: un string representando una frase\n",
        "   \n",
        "Salida: una lista de 0s y 1s, con la misma longitud que `palabras` tal que en la posición i tendrá un 1 si la palabra iésima aparece en la frase y 0 en otro caso\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cc4a811",
      "metadata": {
        "id": "0cc4a811"
      },
      "outputs": [],
      "source": [
        "def palabrasEnFrase(palabras,frase):\n",
        "    # solución\n",
        "    return [ 0 if p not in frase else 1 for p in palabras]\n",
        "\n",
        "# salida esperada: [1, 0, 1, 0, 1, 0]\n",
        "palabrasEnFrase([\"PRINCESA\",\"RAMA\", \"RANA\", \"PRINCIPE\",\"POZO\", \"GOZO\"],\n",
        "                \"HABÍA UNA VEZ UNA LINDA RANA QUE AL CAERSE A UN POZO SE CONVIRTIÓ EN UNA HORRIBLE PRINCESA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e7cafda",
      "metadata": {
        "id": "5e7cafda"
      },
      "source": [
        "A partir de `frecuentes`(ejercicio 3) y `frases` (ejercicio 4) queremos obtener una lista `pertenencia`donde\n",
        "\n",
        "1) `pertenencia` tiene tantos elementos como `frases` (uno por frase)\n",
        "2) El elemento i-ésimo de `pertenencia` es una lista de  1s y 0s con la misma longitud que `frecuentes` indicando si cada palabra de `frecuentes` está en la frase i-ésima.\n",
        "\n",
        "Con otras palabras pertenencia es una lista de listas donde `pertenencia[i][j] == 1` si `frecuentes[j]` aparece en `frases[i]`, y 0 en otro caso\n",
        "\n",
        "Nota: conviene usar la función del ejercicio 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77255c50",
      "metadata": {
        "id": "77255c50"
      },
      "outputs": [],
      "source": [
        "pertenencia = [palabrasEnFrase(frecuentes,f) for f in frases]\n",
        "pertenencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3032a7cc",
      "metadata": {
        "id": "3032a7cc"
      },
      "outputs": [],
      "source": [
        "# para probar;\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(pertenencia,columns=frecuentes)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ab39877",
      "metadata": {
        "id": "5ab39877"
      },
      "source": [
        "El siguiente código elimina aquellas filas que no tienen ninguna de las palabras más frecuentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "094ac13c",
      "metadata": {
        "id": "094ac13c"
      },
      "outputs": [],
      "source": [
        "df2 = df[df!=0].dropna(how=\"all\").fillna(0).reset_index(drop=True)\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e503072b",
      "metadata": {
        "id": "e503072b"
      },
      "source": [
        "Mostrar las parejas de columnas diferentes en `df2`que tengan una correlación superior a 0.25 en valor absoluto\n",
        "\n",
        "Ayuda: Si llamamos correlaciones al dataframe generado por corr, podemos acceder a la correlación de la columna c1 con la c2 (con c1,c2 nombres de columnas de df2) mediante `correlaciones.loc[c1,c2]`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "727d2184",
      "metadata": {
        "id": "727d2184"
      },
      "outputs": [],
      "source": [
        "correlaciones = df2.corr()\n",
        "for c1 in df2.columns:\n",
        "    for c2 in df2.columns:\n",
        "        if c1<c2:\n",
        "            v = correlaciones.loc[c1,c2]\n",
        "            if abs(v)>0.20:\n",
        "                print(c1,c2,v)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c0305f1",
      "metadata": {
        "id": "8c0305f1"
      },
      "source": [
        "¿Qué dos ingredientes parece más improbable encontrar juntos a la vista de estas correlaciones?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "207a45fb",
      "metadata": {
        "id": "207a45fb"
      },
      "source": [
        "Solución:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "162d15d6",
      "metadata": {
        "id": "162d15d6"
      },
      "source": [
        "Análisis de sentimiento\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install accelerate -U"
      ],
      "metadata": {
        "id": "OEJ_iv_oiNLg"
      },
      "id": "OEJ_iv_oiNLg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0c09a59",
      "metadata": {
        "id": "f0c09a59"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from pysentimiento import create_analyzer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "analizador_py_sent = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
        "#analizador_py_odio = create_analyzer(task=\"hate_speech\", lang=\"es\")\n",
        "analizador_py_emo = create_analyzer(task=\"emotion\", lang=\"es\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "746e22ea",
      "metadata": {
        "id": "746e22ea"
      },
      "outputs": [],
      "source": [
        "msjs_tor = [\"Me encanta la tortilla de patata con cebolla\",\n",
        "            \"No puedo creer que haya gente que tome la tortilla con cebolla\",\n",
        "            \"sincebollista hasta la muerte, abajo la cebolla\",\n",
        "            \"La cebolla no se toca\",\n",
        "            \"Ojalá desaparezcan del mundo todos los cebollistas\"]\n",
        "msjs_vacas = [\"¡Qué caro está todo!\",\n",
        "              \"Espero que mi equipo gane la liga este año\",\n",
        "              \"Qué pena que el servicio al cliente sea tan lento\",\n",
        "              \"No me ha gustado nada el producto, pésima relación calidad/precio\",\n",
        "              \"Recomendaría este hotel, lo mejor la limpieza\",\n",
        "              \"Olvídame fuerte, igual que te amé\"]\n",
        "msjs = msjs_tor + msjs_vacas\n",
        "\n",
        "for frase in msjs:\n",
        "    analisis_sent = analizador_py_sent.predict(frase)\n",
        "    analisis_emo = analizador_py_emo.predict(frase)\n",
        "    print(frase)\n",
        "    print(\"Sentimiento\", analisis_sent)\n",
        "    print(\"Emoción\",analisis_emo)\n",
        "    print(\"=\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0d22bf5",
      "metadata": {
        "id": "c0d22bf5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}