{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelCaballero/Julio24/blob/main/code/09preprocesado_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj_n2gLkzmUI"
      },
      "source": [
        "# Introducción a la ciencia de datos con Python\n",
        "### Rafa Caballero\n",
        "\n",
        "##  Preprocesado\n",
        "\n",
        "Veamos cómo se pueden utilizar las características de Pandas para preprocesado básico de los datos\n",
        "\n",
        "\n",
        "\n",
        "### Índice\n",
        "[Duplicados](#Duplicados)<br>\n",
        "[Ver nulos](#Ver-nulos)<br>\n",
        "[Valores Imputados](#Valores-Imputados)<br>\n",
        "[Eliminar nulos](#Eliminar-nulos)<br>\n",
        "[Tranformación de valores](#Transformación-de-valores)<br>\n",
        "[Normalización y estandarización](#normalizacion)<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chMyb2sOzmUK"
      },
      "source": [
        "<a name=\"Duplicados\"></a>\n",
        "### Duplicados\n",
        "\n",
        "A menudo nos interesaría eliminar datos duplicados ya sean filas o columnas que pueden influir negativamente en nuestros resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbiN_aiizmUL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame({'k1': ['a'] * 3 + ['b'] * 4,\n",
        "                  'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FeFI008zmUN"
      },
      "source": [
        "El método `duplicated` devuelve una serie de booleanos que indican si la fila correspondiente está duplicada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLFV02y9zmUO"
      },
      "outputs": [],
      "source": [
        "data.duplicated()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeK5bNFIzmUP"
      },
      "source": [
        "Vemos que tiene toda la apariencia de un filtro; ahora es fácil eliminar duplicados usando el operador not para arrays ~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NsgQF_9zmUP"
      },
      "outputs": [],
      "source": [
        "data[~data.duplicated()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aixHt-QCzmUQ"
      },
      "source": [
        "Otra forma de hacerlo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUSgEOZqzmUR"
      },
      "outputs": [],
      "source": [
        "data.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDjlR1i5zmUR"
      },
      "source": [
        "Se puede limitar el borrado a ciertas columnas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRTOs1kzzmUS"
      },
      "outputs": [],
      "source": [
        "data['v1'] = range(7)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBNHVhk0zmUS"
      },
      "outputs": [],
      "source": [
        "data.drop_duplicates(['k1'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZab6zpTissY"
      },
      "source": [
        "<a name=\"Ver-nulos\"></a>\n",
        "### Ver nulos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d-CCfuEzmUU"
      },
      "source": [
        "Lo primero que hay que indicar es que en general los valores NaN/missing/nulos no son un problema para Pandas, la mayoría de las funciones los aceptan sin problemas.\n",
        "\n",
        "Sin embargo, en la librería de machine learning `sklearn` sí puede dar error, por lo que puede que queramos eliminarlos.\n",
        "\n",
        "Empezamos creando un ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wolfaa7vzmUU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "datos= [\n",
        "    [601166, 20111231,  601166,  np.nan,   np.nan, np.nan],\n",
        "    [600036, 20111231,  600036,  np.nan,    12, np.nan],\n",
        "    [600016, 20111231,  600016,  4.3,   np.nan, np.nan],\n",
        "    [601009, 20111231,  601009,  np.nan,   np.nan, np.nan],\n",
        "    [601939, 20111231,  601939,  2.5,  8],\n",
        "    [100001, 20111231,  100001,  np.nan,   np.nan, np.nan],\n",
        "    [np.nan, np.nan,  np.nan,  np.nan,   np.nan, np.nan]\n",
        "\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(datos,columns=['A','B','C','D','E','F'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5RODZjhzmUU"
      },
      "source": [
        "Lo primero sería contar el número de nulos por columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8egWM8nzmUV"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6XtP7RczmUW"
      },
      "source": [
        "**Ejercicio 1** ¿Cómo contar el total de nulos?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pcX6MkOzmUW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAGrPrgLhxQS"
      },
      "source": [
        "También podemos verlo por filas con axis; axis=0 se refiere a filas y axis=1 a columnas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_ecaVaBh0MP"
      },
      "outputs": [],
      "source": [
        "df.isna().sum(axis=1) # axis =1 número de columnas nulas en cada fila"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bss9JqEMiELX"
      },
      "source": [
        "Filas con algún nulo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46KgNyJMiHVo"
      },
      "outputs": [],
      "source": [
        "(df.isna().sum() > 0).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc-8jAWriIX3"
      },
      "source": [
        "Número de columnas con algún nulo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgcpB1WniKFg"
      },
      "outputs": [],
      "source": [
        "(df.isna().sum(axis=1) > 0).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Qué columnas tienen nulos?"
      ],
      "metadata": {
        "id": "WQm15cvvapjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns[df.isnull().sum() >0]"
      ],
      "metadata": {
        "id": "uAEgYxg6af1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Método propuesto por nuestro compañero Andrés:\n"
      ],
      "metadata": {
        "id": "S8eA7Kzk0cNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = pd.DataFrame({'type': df_google.dtypes, 'hasNull': df_google.isnull().sum() })\n",
        "df_result"
      ],
      "metadata": {
        "id": "FNLx9rqE0fP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Número de columnas con todo nulos"
      ],
      "metadata": {
        "id": "ak6WNUxMbGAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(df.isna().sum() == df.shape[0]).sum()"
      ],
      "metadata": {
        "id": "5gAKxjbZayIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qué columnas tienen todo a nulos"
      ],
      "metadata": {
        "id": "uoahjDczbbWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columnasANulo = df.columns[df.isna().sum() == df.shape[0]]\n",
        "columnasANulo"
      ],
      "metadata": {
        "id": "UJ-5G_RJbfyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quitar todas las columnas que solo tienen nulos"
      ],
      "metadata": {
        "id": "SHW_VNYYiAYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.drop(columns=columnasANulo)\n",
        "df2"
      ],
      "metadata": {
        "id": "HY-oGp9QiH_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kAhTw1Xi-J3"
      },
      "source": [
        "\n",
        "Sobre todo en el caso de dataframes con gran cantidad de datos utilizar una visualización adecuada puede ayudar a entender el origen de los nulos. La biblioteca missingno puede ser muy útil en este sentido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A8jnjOGi5oP"
      },
      "outputs": [],
      "source": [
        "#!pip install missingno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVSrLIsmjPcn"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import missingno as msno\n",
        "%matplotlib inline\n",
        "\n",
        "url=\"https://github.com/RafaelCaballero/tdm/blob/master/datos/tusa2020.csv?raw=true\"\n",
        "df = pd.read_csv(url)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPjDlHoENVFl"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnkA0tFpNVFm"
      },
      "source": [
        "Vemos que `coordinates`solo tiene nulos; podemos quitarla directamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yNK5XSNNVFm"
      },
      "outputs": [],
      "source": [
        "df2 = df.drop(columns=[\"coordinates\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux5q0piFNVFm"
      },
      "source": [
        "Un \"histograma de nulos\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kdSRL4LNVFm"
      },
      "outputs": [],
      "source": [
        "msno.bar(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76wSIFyiNVFm"
      },
      "source": [
        "Otra forma, que puede resultar más informativa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtruAA3bNVFn"
      },
      "outputs": [],
      "source": [
        "msno.matrix(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1quflM0mNVFn"
      },
      "source": [
        "En este gráfico los nulos aparecen como líneas blancas ¿llama algo la atención al comparar unas columnas con otras?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ9lF0CANVFn"
      },
      "source": [
        "El método `heatmap` nos ayudará a relacionar columnas con nulos entre sí:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVf-NWdnNVFn"
      },
      "outputs": [],
      "source": [
        "msno.heatmap(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El valor 1 indica que los nulos suceden a la vez. ne la misma fila, y el -1 que lo hacen en filas contrarias; vemos que RT_source es nulo cuando el resto no lo son y al reves\n",
        "\n",
        "¿Que pasaría si borramos las filas que tienen algún nulo?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vW8JSzMJO9K-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cviZ-QLzmUT"
      },
      "source": [
        "<a name=\"Eliminar-nulos\"></a>\n",
        "### Eliminar nulos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpIC-8q1zmUW"
      },
      "source": [
        "Por defecto, `dropna` borra las filas que tienen algún NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J19Cu6VnzmUW"
      },
      "outputs": [],
      "source": [
        "df2 = df.dropna()\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJghw-ndzmUW"
      },
      "source": [
        "Problema: hemos borrado el dataframe entero, porque las filas que no tienen nulo en source_rt las tienen en el resto. Una alternativa más conservadora es borrar filas tienen todas sus columnas a  NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUa28s85zmUW"
      },
      "outputs": [],
      "source": [
        "df.dropna(how=\"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora no hemos borrado ninguno!! todas las filas tienen algún componente no nulo"
      ],
      "metadata": {
        "id": "ASH-NyjNNlCW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn87bqhZzmUW"
      },
      "source": [
        "**Ejercicio 2** También se pueden borrar columnas añadiendo axis=1 para indicar que trabaje por columnas. Hacerlo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3vZUYxGzmUX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyh8U3jOzmUX"
      },
      "source": [
        "También se pueden conservar solo las que tienen a partir un cierto número de valores distintos de 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMly924WzmUX"
      },
      "outputs": [],
      "source": [
        "df.dropna(thresh=7) # probar a poner 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et7t3ikfzmUX"
      },
      "source": [
        "Finalmente, podemos indicar que borre solo las que tiene nulos en una cierta columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inZGum1hzmUY"
      },
      "outputs": [],
      "source": [
        "df.dropna(subset=['lang'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7XmEkykhdn_"
      },
      "source": [
        "**Comentario**  La eliminación de nulos puede ser complicada; quizás perdiendo información ya que al quitar los nulos quitamos también otros datos potencialmente valiosos. Es conveniente hacer un estudio detallado de dónde aparecen los nulos y qué efectos tienen las distintas medidas que pueden ser\n",
        "\n",
        "\n",
        "\n",
        "*   Eliminarlos, hay que ver si por filas, por columnas o por ambas y en qué orden\n",
        "*   Sustituirlo por un valor adecuado, por ejemplo la media de los valores o la interpolación mediante una función. **Nunca** sustituirlos por un valor mágico, que afectará a nuestros análisis\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOGrzxSZo6Fp"
      },
      "source": [
        "**Ejercicio 3**\n",
        "Separar el dataframe df2 en dos, uno df_RT con los valores RT_source distinto de  null y otro df_original con  los valores RT_source a null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SK7TAvlsSRo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyhv_qZys9JQ"
      },
      "source": [
        "**Ejercicio 4**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "¿Eliminarías alguna columna de alguno de los dos dataframes por tener nulos?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJq1tYtKtF9A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SarbCOV6wKjQ"
      },
      "source": [
        "**Consejo** En ocasiones es mejor no eliminar a priori los nulos porque puede ser que hagamos distintos análisis con distintas columnas, en ese caso eliminaremos solo tras obtener el dataframe auxiliar conl as columnas necesarias, reduciendo la pérdida de información"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"Valores-Imputados\"></a>\n",
        "### Valores Imputados\n",
        "\n",
        "¿Qué hacer con los nulos?\n",
        "Si hay columnas con muy pocos datos válidos y que no resultan imprescindibles se pueden borrar\n",
        "\n",
        "Si hay muy pocas filas con un valor nulo (representan un tanto por cierto muy pequeño, menor del 1%) se pueden eliminar\n",
        "\n",
        "Si el número de nulos es muy alto una posibilidad es imputar el valor. Las formas típicas de imputar:\n",
        "\n",
        "* La mediana\n",
        "* La media\n",
        "* La moda (también vale para variables nominales)"
      ],
      "metadata": {
        "id": "Uz5uVyuPqECY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/contaminacionFinal.csv\"\n",
        "df_conta = pd.read_csv(url)\n",
        "msno.matrix(df_conta)"
      ],
      "metadata": {
        "id": "PQccvj8EpUB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la columna 6 queremos reemplazar el valor por el valor medio; para eso utilizaremos un [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)"
      ],
      "metadata": {
        "id": "Z1Su1xJDpfnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "df_imputed = df_conta.copy() # una copia para no cambiar el original\n",
        "\n",
        "metodo = SimpleImputer( strategy='mean') # si se prefiere la mediana cambiarlo por media\n",
        "\n",
        "modelo = metodo.fit(df_conta[[\"6\"]]) # aquí calcula la media y prepara el \"imputador\"\n",
        "\n",
        "df_imputed[[\"6\"]]  = modelo.transform(df_conta[[\"6\"]]) # aquí se rellenan los nulos\n",
        "\n",
        "msno.matrix(df_imputed)"
      ],
      "metadata": {
        "id": "o_qb0W51pi3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRloiKiAzmUY"
      },
      "source": [
        "\n",
        "<a name=\"Transformación-de-valores\"></a>\n",
        "### Tranformación de valores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwAfoS0GzmUY"
      },
      "source": [
        "Empezamos con un ejemplo de asignaturas y los créditos que representan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "calOBgBEzmUZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = {'nombre': ['A', 'B', 'C', 'D','E', 'F', 'G'],\n",
        "        'creditos': [4,  6,  4.5, 6,  6, 4.5,  12]}\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKF3RfFlzmUZ"
      },
      "source": [
        "**Ejercicio 6** Suponiendo que un crédito son 10 horas lectivas, añadir una columna que 'horas' con los créditos multiplicados por 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjcCaVDAzmUZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYbfeiKuzmUa"
      },
      "source": [
        "Un caso especial: reemplazar todos los valores concretos. Supongamos que todas las asignaturas de 12 créditos pasan a ser de 16. Podemos hacer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uidtn18bzmUa"
      },
      "outputs": [],
      "source": [
        "df2 = df.replace(12, 16)\n",
        "# recordar que hay que recalcular\n",
        "df2['horas'] = df2.creditos*10\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87fuyo9VzmUa"
      },
      "source": [
        "Supongamos ahora que queremos añadir una columna 'tipo' que vale 'optativa' para todas las asignaturas de 4.5 créditos o menos y 'troncal' para asignaturas de más de 4.5 créditos.\n",
        "\n",
        "Lo primero será escribir una función que haga esta transformación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cs-lhwEXzmUa"
      },
      "outputs": [],
      "source": [
        "def calcula_tipo(creditos):\n",
        "    if creditos>4.5:\n",
        "        r = 'troncal'\n",
        "    else:\n",
        "        r = 'optativa'\n",
        "    return r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STR0e0p7zmUb"
      },
      "source": [
        "Ahora la aplicamos a columna créditos con la función `map` que aplica una función a todos los elementos de una columna:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6wR_3NgzmUb"
      },
      "outputs": [],
      "source": [
        "df['tipo'] = df.creditos.map(calcula_tipo)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czM2avwTzmUb"
      },
      "source": [
        "También se puede hacer directamente con una función lambda, que nos permite usar funciones sin definirlas primero:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDbBYEC3zmUb"
      },
      "outputs": [],
      "source": [
        "df['tipo2'] = df.creditos.map(lambda x:'optativa' if x<=4.5 else 'troncal')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando se quieren aplicar funciones específicas de fechas y de strings tendremos que usar los cualificadores `dt` y `str`"
      ],
      "metadata": {
        "id": "noyjlfB0BDsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"tipo2\"] = df[\"tipo2\"].str.upper()\n",
        "df"
      ],
      "metadata": {
        "id": "OirJ_yI9BVpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou6LVh_ivIY4"
      },
      "source": [
        "<a name=\"normalizacion\"></a>\n",
        "### Normalización y estandarización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agrxjrXDvcYX"
      },
      "source": [
        "Vamos a ver estas dos formas de ajustar los datos con un ejemplo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vsu-hN5azmUc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "fich = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/madrid/contmettraf.csv\"\n",
        "df = pd.read_csv(fich,parse_dates=[\"FECHAH\"])\n",
        "df.index = df[\"FECHAH\"]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j38JtnZ_waPm"
      },
      "source": [
        "#### Normalización\n",
        "\n",
        "Supongamos que queremos hacer una gráfica sencilla de NO y CO\n",
        "\n",
        "Primero vamos a escribir código para obtener un dataframe `dfEne21` que solo tenga las filas de df que correspondan al mes 1 de 2021. Esto se puede hacer filtrando el mes y el año (se utiliza .dt. para indcar a pandas que es una fecha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKsC8oNowlYw"
      },
      "outputs": [],
      "source": [
        "filtro = (df.FECHAH.dt.month == 1) & (df.FECHAH.dt.year == 2021)\n",
        "dfEne21 = df[filtro]\n",
        "dfEne21\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LT-W8LCxVSo"
      },
      "source": [
        "**Ejercicio 8** Escribir código para obtener un dataframe df2 a partir de `dfEne21` que solo tenga la columna \"CO\" y \"NO\". Eliminar  además de df2 todas las filas con algún nulo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qnendvcxmxf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZODFiTY-xCo3"
      },
      "source": [
        "Podemos hacer la gráfica así de fácil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwELPE9-xBwv"
      },
      "outputs": [],
      "source": [
        "df2.iloc[100:300,:].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oahZnBMu0QAA"
      },
      "source": [
        "¿Cuál es el problema? que está en escalas diferentes. y el CO apenas se ve. Vamos a *normalizar* las columnas con la fórmula\n",
        "\n",
        "X_new = (X - X_min)/(X_max - X_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgvSFm3H0gvg"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "metodo = MinMaxScaler()\n",
        "escalador = metodo.fit(df2)\n",
        "escalados = escalador.transform(df2)\n",
        "df3 = pd.DataFrame(escalados,columns=df2.columns)\n",
        "df3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5fowalG1RQP"
      },
      "outputs": [],
      "source": [
        "df3.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS4B_Plt4AIA"
      },
      "outputs": [],
      "source": [
        "df3.iloc[100:300,:].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CRDd52U4QWo"
      },
      "source": [
        "### Estandarización\n",
        "\n",
        "Para algunos tests y comparaciones nos puede interesar que las distribuciones tengan media 0 y desviación típica 0. Esto se hace con la fórmula\n",
        "X_new = (X - mean)/Std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU5raDlj4ZH3"
      },
      "outputs": [],
      "source": [
        "df[ [\"TEMPERATURA\",\"HUMEDAD RELATIVA\"]].hist(bins=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyuUNnq-5DBX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "df2 = df[[\"TEMPERATURA\",\"HUMEDAD RELATIVA\"]].dropna()\n",
        "metodo = StandardScaler()\n",
        "escalador = metodo.fit(df2)\n",
        "escalados = escalador.transform(df2)\n",
        "df3 = pd.DataFrame(escalados,columns=df2.columns)\n",
        "df3.hist(bins=40)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}