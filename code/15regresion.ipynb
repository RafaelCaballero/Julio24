{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelCaballero/Julio24/blob/main/code/15regresion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB6auQk-pe7J"
      },
      "source": [
        "# Introducción a la ciencia de datos con Python\n",
        "### Rafa Caballero\n",
        "\n",
        "## Regresión lineal\n",
        "\n",
        "### Índice\n",
        "[Obtención del modelo](#modelo)<br>\n",
        "[Afinando el error](#error)<br>\n",
        "[Intervalo de confianza](#intervalo)<br>\n",
        "[Mejorando el modelo](#mejorando)<br>\n",
        "[Lasso y Ridge](#lasso)<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CALEyEvRqVi4"
      },
      "source": [
        "Antes de empezar comprobamos la versión de sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af43e7rcqVi5"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "sklearn.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLdmkmTdqVi8"
      },
      "source": [
        "Si se quiere actualizar ejecutar el siguiente código (y después Kernel - Restart)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWLTYUgQqVi-"
      },
      "outputs": [],
      "source": [
        "#!pip  install scikit-learn --upgrade --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLr3aKTDpkF4"
      },
      "source": [
        "<a name=\"modelo\"></a>\n",
        "## Obtención del modelo\n",
        "\n",
        "Empezamos cargando un fichero con las notas de las pruebas PISA. Recordamos la importancia del preprocesado, pero es aquí nos dan ya los datos preparados para que nos centremos en la regresión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wZOKxF0sUs2"
      },
      "outputs": [],
      "source": [
        "# Paso 0: Carga y preparación del fichero\n",
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/pisaDataClean.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz0bK6B48HGS"
      },
      "source": [
        "1.- Dividir las columnas en X e y e. Nuestro objetivo será deducir la columna MAT (y) desde dos columnas: SCI y REA, que serán las X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe1EtWSB5nfT"
      },
      "outputs": [],
      "source": [
        "\n",
        "XColumns = [\"SCI\", \"REA\"] # una lista de columnas: las X, las características, las features, las dimensiones...\n",
        "yColumn = \"MAT\"  # la y, siempre una única columna\n",
        "# dividimos en dos; X será un dataframe, y una columna (tipo Series)\n",
        "X = df[XColumns]\n",
        "y = df[yColumn]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7mtFbWjqVjG"
      },
      "source": [
        "2.- Dividir las columnas en X e y en train y test. En este caso ponemos 70% para train y 30% para test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8NRArDOqVjH"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "test = 0.3\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tendremos que\n",
        "\n",
        "*   X = X_train + X_test\n",
        "*   y = y_train + y_test\n"
      ],
      "metadata": {
        "id": "x5s7fJwA0eg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "Mlawia6e1AQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "xh0511Ku1BSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "xFI-j2Th1Caw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxLb1qAb9QxC"
      },
      "source": [
        "3.- Declarar el método y  entrenar con el conjunto train, obteniendo un *modelo*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMyU4DUguOIy"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "metodo = LinearRegression()\n",
        "modelo = metodo.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdcTlraEqVjK"
      },
      "source": [
        "El modelo representa simplemente la recta que mejor ajusta las (X,y) dadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHR9IDl00uwK"
      },
      "outputs": [],
      "source": [
        "modelo.intercept_, modelo.coef_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"La recta de regresión es {yColumn} =\\\n",
        " {round(modelo.coef_[0],3)}*{XColumns[0]} + {round(modelo.coef_[1],3)}*{XColumns[1]} + \\\n",
        " {modelo.intercept_}\")"
      ],
      "metadata": {
        "id": "qpDKh1Sh1Oes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_U6CfhNqVjL"
      },
      "source": [
        "Aunque veremos que estas predicciones las vamos a hacer automáticamente, podríamos escribir por nuestra cuentra una función que las haga:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwntOWFPqVjL"
      },
      "outputs": [],
      "source": [
        "def y_predict(X,modelo):\n",
        "    s = modelo.intercept_\n",
        "    for i,x in enumerate(X):\n",
        "        s += x*modelo.coef_[i]\n",
        "    return s\n",
        "\n",
        "y_predict([400,450],modelo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoM3KvXDqVjL"
      },
      "source": [
        "Vamos a representar gráficamente los datos de entrenamiento y la recta modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "5VhWPesqqVjL"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "fig = plt.figure(figsize=(14,6))\n",
        "\n",
        "# projection='3d' indica que este subplot es en 3d\n",
        "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
        "x = X_train[\"SCI\"]\n",
        "y = X_train[\"REA\"]\n",
        "z = y_train\n",
        "ax.scatter3D( x, y, z)\n",
        "\n",
        "y_1 = y_predict([300,300],modelo)\n",
        "y_2 = y_predict([600,600],modelo)\n",
        "ax.plot3D([300,600],[300,600],[y_1,y_2],color=\"green\")\n",
        "ax.set_zlabel(r\"MAT\", fontsize=10, color=\"blue\")\n",
        "ax.set_xlabel(r\"SCI\", fontsize=10, color=\"blue\")\n",
        "ax.set_ylabel(r\"REA\", fontsize=10, color=\"blue\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35PblQDe-BGD"
      },
      "source": [
        "4.- Ahora predecimos con el test y mostramos el error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XTbywcc-Adz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
        "import math\n",
        "y_pred = modelo.predict(X_test)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "mae = mean_absolute_error(y_test,y_pred)\n",
        "print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP91msC7qVjM"
      },
      "source": [
        "Y completamos la figura mostrando los puntos de entrenamiento, de test y la recta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bfrGeVwvdaM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(14,6))\n",
        "\n",
        "# projection='3d' indica que este subplot es en 3d\n",
        "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
        "x = X_train[\"SCI\"]\n",
        "y = X_train[\"REA\"]\n",
        "z = y_train\n",
        "ax.scatter3D( x, y, z,label=\"train\")\n",
        "\n",
        "y_1 = y_predict([300,300],modelo)\n",
        "y_2 = y_predict([600,600],modelo)\n",
        "ax.plot3D([300,600],[300,600],[y_1,y_2],color=\"green\")\n",
        "ax.set_zlabel(r\"MAT\", fontsize=10, color=\"blue\")\n",
        "ax.set_xlabel(r\"SCI\", fontsize=10, color=\"blue\")\n",
        "ax.set_ylabel(r\"REA\", fontsize=10, color=\"blue\")\n",
        "\n",
        "\n",
        "##### Esto es lo nuevo\n",
        "x = X_test[\"SCI\"]\n",
        "y = X_test[\"REA\"]\n",
        "z = y_test\n",
        "ax.scatter3D( x, y, z,label=\"test\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhmFxRkFCQxj"
      },
      "source": [
        "**Ejercicio 1** Repetir los pasos 1,2,3,4, cambiando tan solo el tamaño del test a 0.95 ¿qué sucede con el error?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfIFll0iqVjN"
      },
      "source": [
        "Este es un ejemplo de overfitting: cuando por alguna razón (en este caso por falta de datos de entrenamiento), el modelo generado se comporta mucho mejor sobre el entrenamiento que sobre el test. Repitamos todo el proceso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xy5LyimdqVjN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwKR6Bd_qVjN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3URF_TgHqVjN"
      },
      "source": [
        "<a name=\"error\"></a>\n",
        "\n",
        "\n",
        "## Afinando el error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGGvL_o5qVjO"
      },
      "source": [
        "**Ejercicio 2** Ejecutar varias veces el código anterior, se verá que se obtiene resultados diferentes ¿en qué punto del código se produce esta variación?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyH7R0vrqVjO"
      },
      "source": [
        "De hecho, si se quieren obtener resultados con una cierta verosimilitud tendremos que repetir el experimento (pasos 2,3,4) varias veces. Vamos a instalar el paquete progress bar para ver cómo progresan los experimentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWfXIM41qVjO"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81qfCDt2qVjO"
      },
      "outputs": [],
      "source": [
        "# Carga del fichero\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
        "import math\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/pisaDataClean.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 1\n",
        "XColumns = [\"SCI\", \"REA\"]\n",
        "yColumn = \"MAT\"\n",
        "X = df[XColumns]\n",
        "y = df[yColumn]\n",
        "\n",
        "veces = 500\n",
        "\n",
        "\n",
        "resultados = []\n",
        "for v in tqdm(range(veces)):\n",
        "    # 2\n",
        "    test = 0.4\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)\n",
        "\n",
        "    # 3\n",
        "    metodo = LinearRegression()\n",
        "    modelo = metodo.fit(X_train,y_train)\n",
        "\n",
        "    # 4\n",
        "    y_pred = modelo.predict(X_test)\n",
        "    r2 = r2_score(y_test,y_pred)\n",
        "    rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "    mae = mean_absolute_error(y_test,y_pred)\n",
        "    bias = (y_test - y_pred).mean()\n",
        "    resultados.append([round(r2,3),round(rmse,3),round(mae,3),round(bias,3)])\n",
        "    #print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")\n",
        "\n",
        "df_errores = pd.DataFrame(resultados,columns=[\"r^2\",\"RMSE\",\"MAE\",\"BIAS\"])\n",
        "df_errores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZd4ra7aqVjP"
      },
      "outputs": [],
      "source": [
        "df_errores.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYVH1BbbqVjP"
      },
      "outputs": [],
      "source": [
        "df_errores.describe().loc[\"mean\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru-DdFmOqVjP"
      },
      "source": [
        "Es fácil hacer una función que haga el trabajo de los experimentos. Podemos usarla para evaluar la regresión con otros datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oN2A2iDZqVjP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evalua_regresion(df,XColumns,yColumn,veces=500):\n",
        "    # 1\n",
        "    X = df[XColumns]\n",
        "    y = df[yColumn]\n",
        "\n",
        "\n",
        "\n",
        "    resultados = []\n",
        "    for v in tqdm(range(veces)):\n",
        "        # 2\n",
        "        test = 0.4\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)\n",
        "\n",
        "        # 3\n",
        "        metodo = LinearRegression()\n",
        "        modelo = metodo.fit(X_train,y_train)\n",
        "\n",
        "        # 4\n",
        "        y_pred = modelo.predict(X_test)\n",
        "        r2 = r2_score(y_test,y_pred)\n",
        "        rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "        mae = mean_absolute_error(y_test,y_pred)\n",
        "        bias = (y_test - y_pred).mean()\n",
        "        resultados.append([round(r2,3),round(rmse,3),round(mae,3),round(bias,3)])\n",
        "        #print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")\n",
        "\n",
        "    df_errores = pd.DataFrame(resultados,columns=[\"r^2\",\"RMSE\",\"MAE\",\"BIAS\"])\n",
        "    return df_errores.describe().loc[\"mean\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTXQbXUXqVjQ"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/pisaDataClean.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 1\n",
        "XColumns = [\"SCI\", \"REA\"]\n",
        "yColumn = \"MAT\"\n",
        "print(evalua_regresion(df,XColumns,yColumn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxdxhixqqVjQ"
      },
      "source": [
        "**Ejercicio 3**\n",
        "\n",
        "- Si se en lugar de predecir \"MAT\" desde \"SCI\" y \"REA\" tuviéramos que predecir \"SCI\" desde las otras dos o \"REA\" desde las otras dos cual daría mejores resultados\n",
        "- Si solo queremos utilizar un atributo, ya sea \"SCI\" o \"REA\" para predecir \"MAT\" ¿cuál usarías?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tWp8kaHqVjQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT-sTM5yqVjQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUt5M55_qVjQ"
      },
      "source": [
        "<a name=\"intervalo\"></a>\n",
        "## Intervalos de confianza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Yc30yJfqVjR"
      },
      "source": [
        "Si ahora ejecutamos varias veces el código veremos que los resultados son bastante estables. Aun así persiste una duda...cuando hagamos una predicción ¿podemos estimar lo lejos que está del valor real?\n",
        "\n",
        "Vamos a poder hacerlo con un par de condiciones:\n",
        "\n",
        "1.- Que el bias sea muy próximo a 0\n",
        "\n",
        "2.- Que el RMSE sea una normal\n",
        "\n",
        "La condición 1 la tenemos; hay que tener en cuenta que un valor de alrededor de -0.1...0.1 en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9G0MMjodqVjR"
      },
      "outputs": [],
      "source": [
        "df.MAT.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krsjTKu-qVjR"
      },
      "source": [
        "es muy pequeño. En cuanto al RMSE por simplificar nos conformamos con \"ver\" el histograma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkt16jKdqVjS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#fig, ax = plt.subplots(figsize=(5, 5))\n",
        "df_errores.RMSE.hist(bins=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPX1iKLxqVjS"
      },
      "source": [
        "Asumiendo que esto es una normal, podemos decir que, con un 95% de probabilidades, para cualquier predicción p el valor real estará en el intervalo\n",
        "\n",
        "[p -2RMSE, p+2RMSE]\n",
        "\n",
        "Este intervalo de confianza se mantiene siempre y cuando estemos (aprox.) dentro del rango de valores usados en el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE2_vTfeqVjS"
      },
      "outputs": [],
      "source": [
        "X_train.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDk_CLvTqVjS"
      },
      "source": [
        "**Ejemplo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R_9T_NIqVjT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/pisaDataClean.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 1\n",
        "XColumns = [\"SCI\", \"REA\"]\n",
        "yColumn = \"MAT\"\n",
        "X = df[XColumns]\n",
        "y = df[yColumn]\n",
        "\n",
        "metodo = LinearRegression()\n",
        "modelo = metodo.fit(X.values,y)\n",
        "\n",
        "p = modelo.predict([[400,450]])[0]\n",
        "\n",
        "p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8VlcUupqVjT"
      },
      "source": [
        "Como el RMSE es aproximadamente 11.75, tendremos que con un 95% de probabilidades el valor real está entre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cxk1CbJnqVjT"
      },
      "outputs": [],
      "source": [
        "RMSE = 11.75\n",
        "(p-1.96*RMSE,p+1.96*RMSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khZNeWQ5qVjT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "df[[\"MAT\"]].hist()\n",
        "plt.plot([p-1.96*RMSE,p-1.96*RMSE],[0,1],color=\"pink\",linewidth=5)\n",
        "plt.plot([p+1.96*RMSE,p+1.96*RMSE],[0,1],color=\"pink\",linewidth=5)\n",
        "plt.plot([p,p],[0,1],color=\"yellow\",linewidth=5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO-DYKN7qVjU"
      },
      "source": [
        "Sin embargo, los siguientes diagramas de residuos nos indican que algo no está funcionando como esperábamos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYf9Rb6WqVjU"
      },
      "outputs": [],
      "source": [
        "X = df[XColumns]\n",
        "y = df[yColumn]\n",
        "\n",
        "x = range(len(y))\n",
        "y_pred = modelo.predict(X.values)\n",
        "plt.scatter(x,y_pred,color=\"red\",s=1)\n",
        "plt.scatter(x,y,color=\"blue\",s=8)\n",
        "for i,v in enumerate(y_pred):\n",
        "    plt.plot([x[i],x[i]], [v-2*RMSE,v+2*RMSE],color=\"green\")\n",
        "#for y_v in y_pred:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCI-AlkwqVjV"
      },
      "outputs": [],
      "source": [
        "x = range(len(y))\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "y_pred = modelo.predict(X.values)\n",
        "ci = 1.96*RMSE\n",
        "for i,v in enumerate(y_pred):\n",
        "    plt.plot([x[i],x[i]], [v,y[i]],color=\"green\")\n",
        "ax.fill_between(x, ( y_pred-ci), ( y_pred+ci), color='b', alpha=.1)\n",
        "ax.scatter(x,y_pred,color=\"red\",s=8)\n",
        "ax.scatter(x,y,color=\"blue\",s=8)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jab_RxvPqVjV"
      },
      "outputs": [],
      "source": [
        "y_pred = metodo.predict(X.values)\n",
        "\n",
        "x_plot = plt.scatter(y_pred, (y_pred - y), c='b')\n",
        "plt.hlines(y=0, xmin= -1, xmax=800)\n",
        "\n",
        "plt.hlines(y=2*RMSE, xmin= -1, xmax=800,color=\"r\")\n",
        "plt.hlines(y=-2*RMSE, xmin= -1, xmax=800,color=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKab0d7XqVjV"
      },
      "source": [
        "<a name=\"mejorando\"></a>\n",
        "## Mejorando el modelo\n",
        "\n",
        "El histograma nos sugiere que quizás el modelo sea mejor si dividimos el conjunto en dos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtlwiMpBqVjV"
      },
      "outputs": [],
      "source": [
        "df2 = df[df[yColumn]<450]\n",
        "X = df2[XColumns]\n",
        "y = df2[yColumn]\n",
        "\n",
        "metodo = LinearRegression()\n",
        "modelo = metodo.fit(X.values,y)\n",
        "\n",
        "r2,RMSE,mae,bias = evalua_regresion(df2,XColumns,yColumn)\n",
        "print(RMSE)\n",
        "\n",
        "x = range(len(y))\n",
        "y_pred = modelo.predict(X.values)\n",
        "plt.scatter(x,y_pred,color=\"red\",s=1)\n",
        "plt.scatter(x,y,color=\"blue\",s=8)\n",
        "for i,v in enumerate(y_pred):\n",
        "    plt.plot([x[i],x[i]], [v-2*RMSE,v+2*RMSE],color=\"green\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3om8d7OqVjW"
      },
      "outputs": [],
      "source": [
        "x_plot = plt.scatter(y_pred, (y_pred - y), c='b')\n",
        "plt.hlines(y=0, xmin= -1, xmax=800)\n",
        "\n",
        "plt.hlines(y=2*RMSE, xmin= -1, xmax=800,color=\"r\")\n",
        "plt.hlines(y=-2*RMSE, xmin= -1, xmax=800,color=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xopzu2a_qVjW"
      },
      "outputs": [],
      "source": [
        "df2 = df[df[yColumn]>=450]\n",
        "X = df2[XColumns]\n",
        "y = df2[yColumn]\n",
        "\n",
        "metodo = LinearRegression()\n",
        "modelo = metodo.fit(X.values,y)\n",
        "\n",
        "r2,RMSE,mae,bias = evalua_regresion(df2,XColumns,yColumn)\n",
        "print(RMSE)\n",
        "\n",
        "x = range(len(y))\n",
        "y_pred = modelo.predict(X.values)\n",
        "plt.scatter(x,y_pred,color=\"red\",s=1)\n",
        "plt.scatter(x,y,color=\"blue\",s=8)\n",
        "for i,v in enumerate(y_pred):\n",
        "    plt.plot([x[i],x[i]], [v-2*RMSE,v+2*RMSE],color=\"green\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alwZ511oqVjW"
      },
      "outputs": [],
      "source": [
        "x_plot = plt.scatter(y_pred, (y_pred - y), c='b')\n",
        "plt.hlines(y=0, xmin= -1, xmax=800)\n",
        "\n",
        "plt.hlines(y=2*RMSE, xmin= -1, xmax=800,color=\"r\")\n",
        "plt.hlines(y=-2*RMSE, xmin= -1, xmax=800,color=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk5fM8gbqVjW"
      },
      "source": [
        "<a name=\"lasso\"></a>\n",
        "##  Ridge y Lasso\n",
        "\n",
        "Variantes de la regresión, resultan son técnicas de regularización utilizadas para prevenir el sobreajuste en modelos de regresión lineal. Tienen características ligeramente diferentes:\n",
        "\n",
        "Ridge: Permite reducir la varianza en presencia de multicolinealidad manteniendo todos los predictores.\n",
        "\n",
        "Lasso: Selecciona de variables (a algunas les puede dar coeficientes 0 --> regularización más extrema y parsimonioso) y obtener un modelo más simple y interpretable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9Vfql0NqVjW"
      },
      "outputs": [],
      "source": [
        "# Carga del fichero\n",
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/pisaDataClean.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 1\n",
        "XColumns = [\"SCI\", \"REA\"]\n",
        "yColumn = \"MAT\"\n",
        "X = df[XColumns]\n",
        "y = df[yColumn]\n",
        "\n",
        "# 2\n",
        "from sklearn.model_selection import train_test_split\n",
        "test = 0.95\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)\n",
        "\n",
        "# 3\n",
        "from sklearn.linear_model import LinearRegression\n",
        "metodo = LinearRegression()\n",
        "modelo = metodo.fit(X_train,y_train)\n",
        "\n",
        "# 4\n",
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
        "import math\n",
        "y_pred = modelo.predict(X_test)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "mae = mean_absolute_error(y_test,y_pred)\n",
        "print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd5nYX7KqVjX"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "modelo = Lasso(alpha=6).fit(X_train, y_train)\n",
        "y_pred = modelo.predict(X_test)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "mae = mean_absolute_error(y_test,y_pred)\n",
        "print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtduLpK2qVjX"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "modelo = Ridge(alpha=6).fit(X_train, y_train)\n",
        "y_pred = modelo.predict(X_test)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "mae = mean_absolute_error(y_test,y_pred)\n",
        "print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIMLrVhKqVjX"
      },
      "source": [
        "ElasticNet combina los dos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EHxLvVjqVjX"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "modelo = ElasticNet(alpha=6, l1_ratio=0.5).fit(X_train, y_train)\n",
        "y_pred = modelo.predict(X_test)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_test,y_pred))\n",
        "mae = mean_absolute_error(y_test,y_pred)\n",
        "print(f\"r^2: {round(r2,3)} RMSE: {round(rmse,3)}, MAE:{round(mae,3)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}